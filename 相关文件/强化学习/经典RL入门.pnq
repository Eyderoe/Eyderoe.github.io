---
sidebar_position: 2
---

# 经典强化学习

第 2 阶段总目标：理解 MDP、值函数、策略函数、贝尔曼方程，掌握 动态规划、蒙特卡洛、TD、Q-Learning、SARSA，能在 FrozenLake 环境上实现并跑通 Q-Learning / SARSA，画出学习曲线

## 马尔可夫决策过程

预计时间：2 day

### 理论

马尔可夫决策过程 MDP 正式地描述了强化学习问题所处的环境，包含五个核心元素 $(S,A,P,R,γ)$

- 状态集 $S$，智能体在任意时刻 $t$ 都处于某个状态 $s_t$，且 $s_t \in S$。状态应该包含所有能帮助智能体做决策的关键信息来满足马尔可夫性
- 动作集 $A$，智能体在某个状态下可以采取的所有可能动作的集合，智能体影响环境的唯一方式
- 转移概率 $P$，$P(s'|s,a)$ 表示在状态 $s$ 下执行动作 $a$ 后，环境转移到下一个状态 $s'$ 的概率。描述了环境的动态特性，它是环境的不确定性的来源
- 奖励函数 $R$，$R(s,a,s')$ 表示状态 $s$ 下执行动作 $a$ 后，环境给予的即时奖励
- 折扣因子 $γ$，$γ \in [0,1)$ 衡量未来奖励相对于即时奖励的现值

策略 $\pi$ 是智能体的行为函数，规定了在任意状态 $s$ 下，智能体应该采取何种动作

### 实践